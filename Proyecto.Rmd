---
title: "R Notebook"
output: html_notebook
---


```{r}
library("readxl")
library("class")
x_raw <- read_excel("./kcmillersean-billboard-hot-100-1958-2017/original/Hot 100 Audio Features.xlsx")
sum(is.na(x_raw$spotify_track_explicit))
x_raw
```
We eliminate the rows where the target variable is missing.

```{r}
billboard <- read.csv("./kcmillersean-billboard-hot-100-1958-2017/original/Hot Stuff.csv",header = TRUE)
billboard
```


```{r}
x_full <- x_raw[!is.na(x_raw$danceability),]
x_full  <- x_full[!is.na(x_full$spotify_track_explicit),]
sum(is.na(x_full$spotify_track_explicit))
x_full
```

```{r}
explicit <- x_full$spotify_track_explicit
x <- x_full[,c(9:22)] 
colnames(x)[1]<-"duration"
colnames(x)[2]<-"popularity"
x
sum(is.na(x))
```
We have to see what to do with mode and time_signature.

Quitar key y time_signature
```{r}
x<-x[,-c(5,14)]
```

```{r}
dim(x)
```

```{r}
# pairs(x[,1:6],col = ifelse(explicit,"red","blue"))
```

```{r}
C <-cor(x)
C
```

```{r}
for(i in 1 : (nrow(C) - 1)) {
  for(j in (i + 1) : ncol(C)) {
    if(abs(C[i, j]) >= 0.5) print(paste0(rownames(C)[i], " - ", colnames(C)[j]))
  }
}
```



```{r}
mu_exp = as.matrix(apply(x[explicit == TRUE,],2,mean))
mu_exp
```

```{r}
mu_nexp = as.matrix(apply(x[explicit == FALSE,],2,mean))
mu_nexp
```

```{r}
apply(x[explicit == TRUE,],2,var)
```

```{r}
apply(x[explicit == FALSE,],2,var)
```

Asumim que les variancies son diferents (s'hauria de fer box m test)

```{r}
sum(explicit == FALSE)
sum(explicit == TRUE)
```
```{r}
hist(x$loudness[explicit == FALSE],freq = FALSE,border = "green",ylim = c(0,0.2))
hist(x$loudness[explicit == TRUE],freq = FALSE,add  = TRUE,border = "red",ylim = c(0,0.2))


```

```{r}
hist(x$speechiness[explicit == FALSE],freq = FALSE,border = "green")
hist(x$speechiness[explicit == TRUE],freq = FALSE,add  = TRUE,border = "red")
```
```{r}
hist(x$danceability[explicit == FALSE],freq = FALSE,border = "green")
hist(x$danceability[explicit == TRUE],freq = FALSE,add  = TRUE,border = "red")
```
```{r}
hist(x$popularity[explicit == FALSE],freq = FALSE,border = "green",ylim = c(0,0.05))
hist(x$popularity[explicit == TRUE],freq = FALSE,add  = TRUE,border = "red",ylim = c(0,0.05))
```
```{r}
hist(x$valence[explicit == FALSE],freq = FALSE,border = "green")
hist(x$valence[explicit == TRUE],freq = FALSE,add  = TRUE,border = "red") 
```

Fem un ànalisi cluster

```{r}
set.seed(123)
xstd = scale(x,scale = TRUE)
c = sample(1:nrow(xstd),1000)
D = dist(xstd[c,])
```


```{r}
hc.ward <- hclust(D,method="ward.D2")
plot(hc.ward,ylab="Distance",main="single linkage (weighted Euclidean)",
xlab="",hang=-1,las=1,cex.main=1)
clusters <- cutree(hc.ward, 2)
table(clusters,explicit[c])
```

Fem un ànalisi lda i veiem l'output de una primera classificació

```{r}
# LDA
library(MASS)
out <- lda(explicit~.,data=x)
plot(out)
```


```{r}
# PCA no separa
pca = princomp(x[c,],cor=TRUE)
plot(pca$scores[,1],pca$scores[,2],col = ifelse(explicit,"red","blue"),asp = 1)
```

## Classificació

ara ens falta fer learn + test i cross validation

```{r}
g = function(prior,S_inv,mu,x){
  x = t(as.matrix(x))
  g = log(prior) - log((2*pi)^(ncol(S_inv)/2)) -1/2*t(x-mu) %*% S_inv %*% (x-mu)
  return(g)
}

dichotomizer = function(xx,prior_exp,prior_nexp,S_exp_inv,S_nexp_inv,mu_exp,mu_nexp){
    class = rep(0, nrow(xx))
    for (i in 1:nrow(xx)){
        dico = g(prior_exp,S_exp_inv,mu_exp,xx[i,])-g(prior_nexp,S_nexp_inv,mu_nexp,xx[i,])
        if (dico > 0) class[i] = 1 
    }
    return(class)
} 

F1 = function(y_true,y_pred){
    positives = c(y_true == 1)
    true_positives = sum(positives) - sum((y_true[positives] - y_pred[positives])^2)
    prec = true_positives/sum(y_pred == 1)
    recall = true_positives/sum(y_true == 1)
    F1 = 2*(prec*recall)/(prec+recall)
    return (F1)
}

Error = function(y_true,y_pred,n){
   return(sum((y_true-y_pred)^2)/n)
}
```

Definim els datasets de Learn i Test a partir del dataset inicial

```{r}
set.seed (4321)
N <- nrow(x)
learn <- sample(1:N, round(0.67*N))
xl = x[learn,]
yl = explicit[learn]
xtest = x[-learn,]
ytest = explicit[-learn]
```

Escollim quina és la millor k

```{r}
# 88 = round(sqrt(nrow(xtest)))
c = rep(0,88)
i=1
while (i < 88){
  nn = knn(scale(xl),scale(xtest),as.factor(yl),k=i)
  sum(nn == "TRUE")
  c[i] = Error(ytest,as.logical(nn),nrow(xtest))
  i = i + 2
  }
which(c == min(c[c!=0]))
```

La millor k és k=11

# Cross Validation

Fem la 10-fold Cross-Validation per escollir el millor model

```{r}
library(MLmetrics)
k=10
error = matrix(, nrow = 3, ncol = 10)
f1 = matrix(, nrow = 3, ncol = 10)
fold_size = nrow(xl) %/% k
for (i in 1:k){
    #Definim els talls que definiran els folds
    init = (i-1)*fold_size
    if(i == 10){
    end = nrow(xl)
    }else{
    end = init + fold_size
    }
    xtraining = xl[-c(init:end),]
    ytraining = yl[-c(init:end)]
    xvalidation = xl[c(init:end),]
    yvalidation = yl[c(init:end)]
    
    #Model0: dichotomizer assuming MVN:
    # Creem el dichotomizer
    # Primer creem les funcions discriminants
    prior_exp = sum(ytraining == TRUE)/nrow(xtraining)
    prior_nexp = 1 - prior_exp
    S_exp = cov(xtraining[ytraining == TRUE,])
    S_nexp = cov(xtraining[ytraining == FALSE,])
    S_exp_inv = solve(S_exp)
    S_nexp_inv = solve(S_nexp)
    prediction0 = dichotomizer(xvalidation,prior_exp,prior_nexp,S_exp_inv,S_nexp_inv,mu_exp,mu_nexp)
    error[1,i] =  Error(as.numeric(yvalidation),prediction0,nrow(xvalidation))
    f1[1,i] = F1_Score(as.numeric(yvalidation),prediction0)
    
    #Model1: glm with binomial family
    mod1 <- glm(ytraining ~ ., data=as.data.frame(xtraining),family=binomial)
    prediction1 = round(predict(mod1,ty="response",
    newdata = as.data.frame(xvalidation)))
    error[2,i] = Error(as.numeric(yvalidation),prediction1,nrow(xvalidation))
    f1[2,i] = F1_Score(as.numeric(yvalidation),prediction1)
    
    #Model2: knn
    k_knn = 11 #escollida a fora
    nn = knn(scale(xtraining),scale(xvalidation),as.factor(ytraining),k=k_knn)
    error[3,i] = Error(yvalidation,as.logical(nn),nrow(xvalidation))
    f1[3,i] = F1_Score(as.numeric(yvalidation),as.numeric(as.logical(nn)))
}

error0 = mean(error[1,])
error1 = mean(error[2,])
error2 = mean(error[3,])
f1_0 = mean(f1[1,])
f1_1 = mean(f1[2,])
f1_2 = mean(f1[3,])
error0
error1
error2
f1_0
f1_1
f1_2
```

Calculem les variàncies des errors

```{r}
vars_errors = apply(error,1,var)
var_f1 = apply(f1,1,var)
vars_errors
var_f1
```

Sembla que el millor és el knn però per molt poc. També és el que té millor variància

Ara reentrenem per tot el dataset de learn

```{r}
# glm
mod <- glm(yl~.,data = as.data.frame(xl),family=binomial(link = "logit"))
pred = round(predict.glm(mod,type = "response",newdata = as.data.frame(xtest)))
F1_Score(as.numeric(ytest),pred)
```

```{r}
# dichotomizer
prior_exp = sum(yl == TRUE)/nrow(xl)
prior_nexp = 1 - prior_exp
S_exp = cov(xl[yl == TRUE,])
S_nexp = cov(xl[yl == FALSE,])
S_exp_inv = solve(S_exp)
S_nexp_inv = solve(S_nexp)
pred_dico = as.data.frame(dichotomizer(xtest,prior_exp,prior_nexp,S_exp_inv,S_nexp_inv,mu_exp,mu_nexp))
F1_Score(as.numeric(ytest),pred_dico[,1],positive = 0)
```

```{r}
# 11-nn
nn = knn(scale(xl),scale(xtest),as.factor(yl),k=11)
F1_Score(as.numeric(ytest),as.numeric(as.logical(nn)))
```




